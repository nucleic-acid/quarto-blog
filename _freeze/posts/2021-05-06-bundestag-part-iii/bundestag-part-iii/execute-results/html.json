{
  "hash": "b9f41429fccd7c980b045ca834558fff",
  "result": {
    "markdown": "---\ntitle: \"Bundestag Part III: Voting on the edge\"\nsubtitle: |\n  Leveraging network analysis tools, the voting behaviour of the deputies in the Bundestag shows similarity-clusters across three legislative periods. A visual analysis.\nauthor:\n  - name: Christian A. Gebhard\n    url: {https://jollydata.blog/about.html}\ndate: 2021-05-06\ndraft: false\ncategories:\n  - R\n  - network analysis\n  - germany\n  - bundestag\n  - politics\nimage: images/ptIII_preview.png\n---\n\n\n\n\n:::{.callout-note collapse=false appearance='default' icon=true}\n## Updates\n2021-09-20\n: minor text refinements, added comment section\n\n2022-09-18\n: ported to quarto\n:::\n\n## Introduction\n\nThis is the third part of the series on the german national parliament, the *Bundestag*. In the previous parts, I got an exploratory feeling for the available open data ([Part I](https://jollydata.blog/posts/2021-03-07-bundestag-part-i/)) and collected more data on the votes / polls in the parliament ([Part II.1](https://jollydata.blog/posts/2021-03-22-bundestag-part-ii1/))^[You can also check out [Part II](https://jollydata.blog/posts/2021-03-14-bundestag-part-ii-web-scraping-the-roll-call-votes/), but I did not use the data collected there. I keep that blog post for reference, but use the data collected and prepared in [Part II.1](https://jollydata.blog/posts/2021-03-22-bundestag-part-ii1/)].\n\nIn this part, I want to explore the voting behaviour of the deputies across all available datasets, spanning three legislative periods from 2009 until now. Sounds great, doesn't it? Well...I knew what I wanted quite early, but getting there took much more time and effort, than expected and I had to tackle challenges I did not foresee before starting this post. If you're interested in them I'll give a summary below, but I plan a whole \"below deck\" post with all that I learned in the process. This way I can focus on the results here. As always, you can jump to [Conclusions] right away.\n\n **Note:** *As (for me) this is the first network analysis project of this size, I cannot guarantee, that the underlying data is represented/handled correctly by the code. I wrote the post with best intentions, with no desire to influence anyone's opinion for the upcoming election. Please take it as what it is: an experimental approach to a new technology by a non-professional. If you find any issues with the code or find anything else, that is not right, please do let me know!*\n\n::::: {.panelset}\n\n::: {.panel}\n[The Ugly]{.panel-name}\n\nThere's one huge problem with the voting data: a lot of implicitly missing data. Some deputies replaced colleagues, that left the parliament short before the next elections, due to personal or other reasons. Some of these replacement-deputies voted in only one or two polls, which means they have more than 600 implicitly missing votes. \n\nBut even if I'd exclude these few extreme \"outliers\" a large portion of the deputies only served in one or two of the three legislative periods. In fact, only about a quarter of them was present in all three periods (s. Figure 1). This makes unsupervised learning difficult at least. Also, I'm not aware of practicable methods to perform clustering on barely categorical data such as the votes \"yes\", \"no\" or \"abstention\".^[I could have dummy-coded / one-hot-encoded the vote categories, but that would have resulted in way more features than deputies, which seemed strange. I might reconsider this in the future...]\n\nSure, I could have split the dataset into the separate legislative periods and continue from there. But I wanted to get a sense of \"longitudinal clusters\" and maybe even compare parlamentarians that served at different times. So I had to find another way: A network analysis.\n:::\n\n\n::: {.panel}\n[The Bad]{.panel-name}\n\nI'm doing the analysis on a midrange 2013 notebook with 8GB of RAM. Building a network is quite straight forward using specialized libraries such as `{igraph}` for R or `{networkx}` in Python. They offer a lot of possibilities. However, the bad thing is the size of the graph I intended to build. At some point I had to juggle 72 million edges between the nodes. The R session frequently hit the boundaries of my memory^[and crashed] more often than I expected, even though I tried many different approaches.\n\nI even tried to rent powerful RStudio servers on *AWS* and *Google Cloud Platform*, but didn't succeed either, as the code was pretty inefficient in the beginning and probably did not leverage the vast computing power and memory on these servers.\n\nI plan to make a piece on my lessons in a separate post.\n:::\n\n::: {.panel}\n[The Good]{.panel-name}\n\nAfter many iterations and improvements, setbacks and redesigns I found a way to juggle the data on my limited hardware: I performed the construction of the graph object and the similarity analysis between the deputies in R with `{igraph}` and then switched to the specialized software [**Cytoscape**](https://cytoscape.org) for layouting and plotting the network:\n\n> \"Cytoscape is an open source software platform for visualizing molecular interaction networks and biological pathways and integrating these networks with annotations, gene expression profiles and other state data. Although Cytoscape was originally designed for biological research, now it is a general platform for complex network analysis and visualization. \"\n> <footer>--- https://cytoscape.org/what_is_cytoscape.html</footer>\n\nAs this Java software was designed to handle extremely large networks, it managed the voting data quite well. Cytoscape comprises many additional plugins or apps for special cases. I only used some of the basic functions of but still enjoyed playing around with the different layout algorithms and tweak the visualizations.\n\nFor this analysis I used Cytoscape version 3.8.2, running on Java 11.0.11.\n\n:::\n\n\n\n::: {.panel}\n[The data]{.panel-name}\n\nThe Bundestag [provides polling data](https://www.bundestag.de/parlament/plenum/abstimmung/liste) for quite a long time going back as PDF reports, but only since around 2010 in machine readable tables. Roll call data since 2009 is available as lists that can be scraped from the website. Unfortunately there is no specific license mentioned for the open data, but the data is offered to \"interested users\" for \"further machine processing\". Sounds good enough for my use.\n\nI'll be using the data hosted in a [github repo](https://github.com/bundestag) called \"bundestag\", which was generated scraping the www.bundestag.de website. Among the different datasets, there are json files with the individual votes linked to the ID number of the ballot and in others there is the meta-data on the ballots including title, date, etc.\nBoth are unofficial data, but I probably couldn't scrape it in a better quality, so I will continue to use this data.\n\nThe data used was published under \"The Unlicense\" with no conditions whatsoever. **I still want to give credit to the [contributors](https://github.com/orgs/bundestag/people) of this repo and thank them for their great and helpful work!**\n\nTo read about how I loaded and prepared this data, please check out [Part II.1](https://jollydata.blog/posts/2021-03-22-bundestag-part-ii1/). \n\n\n:::\n\n:::::\n\n## Preparation\n\nA graph object is composed of *nodes*^[another name is *vertex*] and *edges*. Nodes represent entities, that are connected to one another by edges. For a detailed explanation, check out the [Wikipedia article](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)) on graph theory.  \nFor this post it is sufficient to say that I intend to make the elected deputies the nodes in my graph. They will be connected to one another, if they share a similar voting behaviour in the available poll data.\n\n### Setup and Loading the data\nAs I prepared the data beforehand, I can dive into the analysis right away with only minor adjustments and preparations as described in the next section. First, these are the libraries used:\n\n\n::: {.cell layout-align=\"center\" code_folding='false'}\n\n```{.r .cell-code}\nlibrary(\"tidyverse\")\nlibrary(\"rmarkdown\")\nlibrary(\"igraph\")\n```\n:::\n\n\n\nThe data was prepared to a rectangular/tidy form with every vote of each deputy in each poll as a row/observation. Let's load the dataset and inspect it:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# read the data from file\nvoting_data <- read_csv(here::here(\"data\", \"2021_bundestag\", \"parsed\", \"polls_voting_complete.csv\"), na = \"na\") %>%\n  mutate(name = name_clean) %>%\n  select(-name_clean) \n\nglimpse(voting_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 427,039\n#> Columns: 7\n#> $ state   <chr> \"Sachsen-Anhalt\", \"Mecklenburg-Vorpommern\", \"Bayern\", \"Hamburg…\n#> $ name    <chr> \"Ackermann, Jens\", \"Ahrendt, Christian\", \"Aigner, Ilse\", \"Aken…\n#> $ party   <chr> \"FDP\", \"FDP\", \"CDU/CSU\", \"Die Linke\", \"Die Linke\", \"CDU/CSU\", …\n#> $ vote    <chr> \"nein\", \"nein\", \"nein\", \"ja\", \"ja\", \"nein\", \"ja\", \"enthalten\",…\n#> $ p_id    <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 10…\n#> $ p_date  <date> 2011-07-08, 2011-07-08, 2011-07-08, 2011-07-08, 2011-07-08, 2…\n#> $ p_title <chr> \"Panzerlieferung an Saudi-Arabien\", \"Panzerlieferung an Saudi-…\n```\n:::\n\n```{.r .cell-code}\nsummary(voting_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     state               name              party               vote          \n#>  Length:427039      Length:427039      Length:427039      Length:427039     \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>       p_id           p_date             p_title         \n#>  Min.   :  1.0   Min.   :2009-12-03   Length:427039     \n#>  1st Qu.:172.0   1st Qu.:2012-10-25   Class :character  \n#>  Median :363.0   Median :2015-10-15   Mode  :character  \n#>  Mean   :365.7   Mean   :2015-09-14                     \n#>  3rd Qu.:558.0   3rd Qu.:2018-11-23                     \n#>  Max.   :720.0   Max.   :2021-03-26\n```\n:::\n:::\n\n\nThere are 427039 single votes listed for 655 polls, ranging from 2009-12-03 to 2021-03-26.\n\n### Preparing the data\n\n\nAs mentioned before, the data spans three legislative periods (LP) divided by the elections / reconstitutions of the parliament at 2013-10-22 and 2017-10-24. The periods are named after the serial number of the respective parliament: Bundestag 17, 18 and 19.  \nAlthough I want to make a longitudinal analysis, I still want to see if the LPs do have an influence on the clustering, so I added them as a feature:\n\n<aside>During coding I frequently used \"wp\" or \"w_period\" from the German \"Wahlperiode\", meaning legislative period.</aside>\n\n\n::: {.cell layout-align=\"center\" code_folding='false'}\n\n```{.r .cell-code}\n# split the dataset at the election dates and assign the election period to w_period\nvoting_data_with_wp <- voting_data %>%\n  mutate(\n    w_period = cut(\n      x = p_date,\n      breaks = lubridate::ymd(c(\"2009-12-03\", \"2013-10-22\", \"2017-10-24\", \"2021-03-26\")),\n      labels = c(\"bt17\", \"bt18\", \"bt19\"),\n      include.lowest = TRUE\n    )\n  )\n\n# check success / correct splitting\nvoting_data_with_wp %>% \n  group_by(w_period) %>% \n  summarise(min_date = min(p_date), max_date = max(p_date))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 3 × 3\n#>   w_period min_date   max_date  \n#>   <fct>    <date>     <date>    \n#> 1 bt17     2009-12-03 2013-06-28\n#> 2 bt18     2013-11-28 2017-06-30\n#> 3 bt19     2017-12-12 2021-03-26\n```\n:::\n\n```{.r .cell-code}\n# check the data\nhead(voting_data_with_wp) %>% paged_table()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"state\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"name\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"party\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"vote\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"p_id\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p_date\"],\"name\":[6],\"type\":[\"date\"],\"align\":[\"right\"]},{\"label\":[\"p_title\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"w_period\"],\"name\":[8],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Sachsen-Anhalt\",\"2\":\"Ackermann, Jens\",\"3\":\"FDP\",\"4\":\"nein\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"},{\"1\":\"Mecklenburg-Vorpommern\",\"2\":\"Ahrendt, Christian\",\"3\":\"FDP\",\"4\":\"nein\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"},{\"1\":\"Bayern\",\"2\":\"Aigner, Ilse\",\"3\":\"CDU/CSU\",\"4\":\"nein\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"},{\"1\":\"Hamburg\",\"2\":\"Aken, Jan van\",\"3\":\"Die Linke\",\"4\":\"ja\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"},{\"1\":\"Bremen\",\"2\":\"Alpers, Agnes\",\"3\":\"Die Linke\",\"4\":\"ja\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"},{\"1\":\"Saarland\",\"2\":\"Altmaier, Peter\",\"3\":\"CDU/CSU\",\"4\":\"nein\",\"5\":\"100\",\"6\":\"2011-07-08\",\"7\":\"Panzerlieferung an Saudi-Arabien\",\"8\":\"bt17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nFor the planned graph I need to extract the edge data (more on that later) and the node/vertex data. The latter is a dataframe containing details on the deputies. Apart from the name, the party and the state further data is added: the number of active periods and a factor-column encoding in which period(s) a deputy served.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# select the data of interest\nvoting_data_completed <- voting_data %>%\n  select(name, vote, p_id) %>%\n  arrange(p_id, name)\n\n# select the deputy info of interest\ndeputies <- voting_data_with_wp %>% \n  distinct(name, w_period, .keep_all = TRUE) %>%\n  select(name, party, state, w_period) \n\n# count the number of electoral periods in which a deputy was listed\ndeputies_wps <- deputies %>% \n  count(name) %>% \n  rename(n_wp = n)\n\n# the deputies are further grouped according to the periods in which they served.\n# by calculating the mean of their respective active periods.\ndeputies_wpclust <- deputies %>% \n    mutate(\n    wp_num = as.numeric(str_remove(w_period, \"^bt\"))\n    ) %>% \n  group_by(name) %>% \n  summarise(wp_clust = mean(wp_num))\n\nggplot(deputies_wps, aes(n_wp)) +\n  geom_histogram(bins = 3, fill = jolly_petrol) +\n  scale_x_continuous(breaks = c(1, 2, 3), labels = c(\"1\", \"2\", \"3\"))+\n  labs(\n    title = \"How many legislative periods did the deputies serve?\",\n    subtitle = \"Number of deputies voting for at least one poll in one, two or three legisl. periods.\",\n    x = \"Legislative periods\",\n    y = \"Number of deputies\",\n    caption = \"by jollydata.blog\\nusing data from https://github.com/bundestag\"\n  ) +\n  jolly_theme()\n```\n\n::: {.cell-output-display}\n![Distribution of the number of active legislative periods of all deputies.](bundestag-part-iii_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\ndeputies_complete <- deputies %>% \n  left_join(deputies_wps, by = \"name\") %>% \n  left_join(deputies_wpclust, by = \"name\") %>% \n  mutate(\n    wp_clust_fct = ifelse(n_wp == 3, \"all_wp\", as.character(wp_clust))\n  )\n\ndeputies_distinct <- deputies_complete %>% \n  distinct(name, .keep_all = TRUE)\n```\n:::\n\n\n\n<!-- I then still split the data, even though I did not use the separate sets in the end. -->\n\n\n\n\n## Building the network\nAs mentioned before, I chose a network analysis as approach to cluster the representatives according to their voting behaviour. The process includes three core functions written in R and the later visualiziation in cytoscape.\n\n::::: {.panelset}\n\n::: {.panel}\n\n### The Logic {.panel-name}\n\n\nI posted the code in all detail in the next tab. The logic of the whole process goes as such:\n\n1. In the `compose_graph`-function the votes dataframe is nested under the poll ID, i.e. for each poll ID there is a \"sub-dataframe\" containing the name of the deputy and her/his vote in that poll. Using `purrr::map()` each nested dataframe is passed to the `build_graph_dataframe` function.\n3. In `build_graph_dataframe` the votes of all $N$ deputies in the received poll data are compared to one another, creating a $N\\times N$ matrix, where TRUE means \"voted the same\" and FALSE means \"voted differently\". This boolean matrix is coerced into a numerical matrix of 0s and 1s and interpreted as adjacency matrix of a graph object, which is then converted to an edgelist. This edgelist-dataframe is returned to `compose_graph`.\n3. There, the now nested edgelists are unnested resulting in one huge edgelist (>70 Million edges). This list is a representation of a *multi-graph*, where deputies can be linked to each other by multiple edges (one for each poll, in which they voted the same). Basically, deputies who voted similarly over the time of their career share more common edges.\n4. The multi-edges are then simplified as single, but weighted edges, where the weight is the number of the previously multiple edges connecting two nodes.\n5. The `export_to_cytoscape` function takes several agruments. By default it converts the edgelist to an adjacency matrix (containing the weights of the edges). Calling `cor()` calculates a correlation- or similarity-matrix from the adjacency matrix. \nIn layman's terms, this compares, how mathematically similar^[on a scale from -1: completely different to 1: identical] each deputy is to the voting behaviour of all other representatives.  \nIn technical terms, the resulting correlation matrix contains Pearson's r for the weights in each column^[= deputy]. More specific, the correlation is high, if two deputies share similarly weighted edges to common \"neighbours\".\n6. `export_to_cytoscape` filters the values to a given threshold (default is $r >= 0.5$) and reconstructs a now similarity-weighted edgelist, containing only edges between representatives, whose voting correlated with an r of at least 0.5. This filtered edgelist is then exported for use in Cytoscape.\n7. `export_to_cytoscape` also exports a node-list containing the names and further information on the deputies (state, party affiliation, number of active legislative periods, ...)\n\n:::\n\n::: {.panel}\n\n### The Code {.panel-name}\n\nTo keep the blog post short, I collapsed these three functions. Feel free to unfold the code fot the three above mentioned funcions:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# this is the central function for the construction of the graph/adjacency function\n# it takes a dataframe with name and vote and returns an edgelist for deputies\n# that votes the same in this datafram (= one particular poll)\nbuild_graph_dataframe <- function(source_df) {\n  \n  # pull the votes and construct a named vector\n  votes_temp <- pull(source_df, vote)\n  names(votes_temp) <- pull(source_df, name)\n  \n  # apply the comparison of the whole vector to each vector element\n  # this returns a boolean matrix object with TRUE, when thwo deputies voted \n  # the same, and FALSE in all other cases (voted differently or one vote is missing)\n  # if two deputies were present but abstained from voting this was counted \n  # as equal as well.\n  vote_edges_mat <- sapply(votes_temp, function(x) x == votes_temp)\n  \n  # remove lower triangle (incl. diagonal) of the matrix to prevent duplicated \n  # edges and eigenvectors\n  vote_edges_mat[lower.tri(vote_edges_mat, diag = TRUE)] <- NA\n\n  # convert the matrix to a dataframe. Col-/rownames are the deputies' names due\n  # to using a named vector above. This results in an edgelist with source- and \n  # target nodes.\n  vote_edges_df <- as.data.frame(vote_edges_mat) %>% \n    \n    # convert the rownames to a column of source-nodes\n    tibble::rownames_to_column(\"from\") %>%\n      \n    # convert the columns into a column of target-nodes\n    pivot_longer(-from, names_to = \"to\", names_repair = \"minimal\", values_to = \"same_vote\") %>%\n    \n    # only keep the TRUE edges and remove the now obsolete \"same_vote\" column.\n    filter(same_vote == TRUE) %>%\n    select(from, to)\n  \n  # return the edgelist\n  return(vote_edges_df)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompose_graph <- function(votes_df, deputies_df, slug = \"default_slug\") {\n  # input: \n  # votes_df: a dataframe containing name, vote and p_id columns\n  # deputies_df: a df containing name, party and state cols\n  # slug: a slug to name all resulting csv files\n  \n  \n  # takes the voting data (name, p_id and vote) and nests it under p_id\n  unnested_edgelist <- votes_df %>% \n    group_by(p_id) %>% \n    nest() %>% \n    transmute(edgelists = map(data, build_graph_dataframe)) %>% \n    unnest(edgelists) %>% \n    ungroup() %>% \n    select(-p_id)\n  \n  print(\"Edgelist created. Dimensions:\")\n  print(dim(unnested_edgelist))\n  # store the composed edgelist for future quick access.\n  filename1 <- paste0(slug, \"_allvotes_edgelist.rds\")\n  saveRDS(unnested_edgelist, file = filename1)\n  \n  print(\"Edgelist saved. Building multi edge graph...\")\n  # construct a graph from the edgelist. This creates multiple edges between\n  # most of the deputies (one for each pollin which they voted the same).\n  multi_edge_graph <- graph_from_data_frame(unnested_edgelist, directed = FALSE, vertices = deputies_df)\n  \n  rm(unnested_edgelist)\n  # add default weight = 1 to all edges\n  E(multi_edge_graph)$weight <- 1\n\n  print(\"Multigraph created. Moving on to saving it.\")\n  \n  # save progress\n  filename2 <- paste0(slug, \"_multi_edge_graph.rds\")\n  saveRDS(multi_edge_graph, filename2)\n  print(\"Multigraph saved. Reducing to weighted edge graph...\")\n\n\n  # combine the attributes (aka weights) using the sum function. Now each node\n  # pair is connected by only one edge or none, but the number of same votes is\n  # kept as weight for the particular edge.\n  voting_graph <- simplify(multi_edge_graph, edge.attr.comb = \"sum\")\n  rm(multi_edge_graph)\n\n  # save progress\n  filename3 <- paste0(slug, \"_voting_graph.rds\")\n  saveRDS(voting_graph, filename3)\n  print(\"All saved.\")\n  \n  rm(voting_graph)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexport_to_cytoscape <- function(g, similarity = TRUE, slug = \"default\", sim_threshold = 0.7, with_spearman = FALSE) {\n  # inputs\n  # a graph object g\n  # similarity: chooses if the similarity of the deputies should be exported for\n  # cytoscape (TRUE, default) or the raw edges representing equal votes (FALSE)\n  # slug: prefix for the filenames\n\n  # convert the graph to a dataframe\n  cytoscape_export_df <- igraph::as_data_frame(g, what = \"both\")\n\n  if (similarity == FALSE) {\n\n    # store nodes as nodelist (import as simple csv resulted in errors in cytoscape, so ; is used)\n    filename1 <- paste0(slug, \"_nodelist.csv\")\n    cytoscape_export_df$vertices %>%\n      write_delim(filename1, delim = \";\")\n\n    # store edges as edgelist\n    filename2 <- paste0(slug, \"_edgelist.csv\")\n    cytoscape_export_df$edges %>%\n      write_delim(\"edgelist.csv\", delim = \";\")\n  } else {\n    # convert graph to adjacency matrix. Directly obtaining a regular/full matrix didn't\n    # work, maybe due to memory issues during conversion?\n    # So the graph is converted as sparse matrix (keeping the weights as values) and then to a full matrix\n    A <- as_adjacency_matrix(g, attr = \"weight\", sparse = T)\n    Af <- as.matrix(A)\n    diag(Af) <- 0.001\n\n    if (with_spearman == TRUE) {\n      # perform correlation (spearman)\n      S <- cor(Af, method = \"spearman\")\n      filename3 <- paste0(slug, \"_spearman_\", sim_threshold, \"nodelist.csv\")\n      filename4 <- paste0(slug, \"_spearman_\", sim_threshold, \"edgelist.csv\")\n    } else {\n      # perform correlation (pearson)\n      S <- cor(Af)\n      filename3 <- paste0(slug, \"_pearson_\", sim_threshold, \"nodelist.csv\")\n      filename4 <- paste0(slug, \"_pearson_\", sim_threshold, \"edgelist.csv\")\n    }\n\n    # set diagonal to 0\n    diag(S) <- 0\n\n    # convert back to graph (\"similarity graph\")\n    sim_graph <- graph_from_adjacency_matrix(S, weighted = TRUE, mode = \"undirected\")\n\n    # convert graph to dataframe (edgelist including weight column)\n    sim_df <- igraph::as_data_frame(sim_graph, what = \"edges\")\n\n    # filter for edges with a high weight (aka connecting similar deputies) and\n    # write to file for later import into cytoscape\n\n    sim_df %>%\n      filter(weight > sim_threshold) %>%\n      write_delim(filename4, delim = \";\")\n\n    nodelist_df <- igraph::as_data_frame(g, what = \"vertices\")\n    nodelist_df %>%\n      write_delim(filename3, delim = \";\")\n  }\n}\n```\n:::\n\n\n\nThe following code passes the previously prepared data to the above functions.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# run function for the bt17 data\ncompose_graph(voting_data_completed, deputies_distinct, slug = \"all_wpcluster\")\n\n# resulting graph object are stored to \"all_wpcluster_voting_graph.rds\"\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n:::\n\n:::::\n\n## Visually analysing the network\n\nFinally, the data is in the right shape for a visual representation of the graph!\nAs mentioned above the software Cytoscape is used. After loading the edges and nodes into the work environment in Cytoscape, the graph layout is computed. For this the \"Prefuse Force Dîrected Layout\" is used with the addition, that the edge-weights are being respected.\n\n\n>The force-directed layout is a layout based on the “force-directed” paradigm. This layout is based on the algorithm implemented as part of the prefuse toolkit provided by Jeff Heer. \n> <footer>--- https://manual.cytoscape.org/en/3.8.2/Navigation_and_Layout.html?highlight=prefuse</footer>\n\nThe nodes and edges are positioned according to a simulated physical environment, \"by assigning forces among the set of edges and the set of nodes, based on their relative positions, and then using these forces either to simulate the motion of the edges and nodes or to minimize their energy\"^[For more information on force-directed layouts, there is a [Wikipedia article](https://en.wikipedia.org/wiki/Force-directed_graph_drawing).]\n\nNote that the distances between nodes are not proportional to the mathematical similarity, nor does proximity necessarily mean strong similarity in voting behaviour. The layout algorithm optimizes the node positions by approximation, so clusters are generally tightly interlinked within, but few connections to the next cluster allows the clusters to stay apart. However, keep in mind, that these results are not as accurate, as e.g. clustering algorithms in a PCA.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![A force-directed layout of the parlamentarians of three legislative periods. The deputies are generally clustered into govrernment vs oppositionn. Within these superclusters there is a separation into clusters of deputies active in only one legislative period, while they are connected by deputies serving two or all three periods. Graph created with Cytoscape, using the weighted 'Prefuse Force Dîrected Layout'. Dotted lines were added afterwards to indicate and annotate the clusters. Political parties: CDU/CSU (black), SPD (red), Die Grünen (green), Linke (purple), FDP (yellow), AfD (blue).](images/wp_clust_marked_400.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThe above image shows a pleasing clustering into party affiliation and legislative periods. For a closer look, here is the [full size version](images/wp_clust_marked.png). A more detailed view, where the nodes have been spread out, so that the representatives' names fit as a label can be found [here](images/wp_clust_detail2.png). The dotted lines are there to indicate \"regions\" not clear boundaries.\n\nThere are a few findings that I want to point out:\n\n- There is a clear overall separation between the governing coalitions and the opposing parties.\n- As the *FDP* was governing in BT17, was not elected into BT18 and rejoined the Bundestag in BT19 they are split into two groups connected by only a few deputies, that were present in both LPs.\n- The deputies of the opposition are roughly grouped into two distant clusters of deputies serving only in BT17 and BT19. Inbetween they are linked by those representatives who served in two or all three LPs. As they do have common votes with either or both \"sides\", they connect the BT17 and BT19 clusters nicely.\n- The opposition clusters even show a quite distinguishable \"longitudinal\" clustering, as the two strains of *Die Grünen* and *Die Linke*  do not mix much and run more or less parallel but separate across the three legislative periods. I hoped to see something like that.\n- The BT17-Opposition-Cluster also contains the *SPD* deputies that were part of the opposition in BT17. This cluster is linked to the *SPD*-deputies that also served in the governing coalition of BT18.\n\n## Conclusions\nThe goal of this post was to visually cluster the voting behaviour and compare it to party membership and legislative period.\n\nThe results above show, that this was achieved and the plot contains interesting findings both in the overview version (Fig. 2), as well  as in the detailed, labeled version.\n\nAfter this exploratory visual analysis I want to dive deeper into a more accurate analysis. This will be part of a new blog post.\nIf you're interested in the technical hurdles I had to overcome during the above analysis, check out my (soon to be published) \"below deck\" companion post for this series.\n\n## Comments\n\nDid you also have troubles handling large data in igraph or ggraph and found a way to minimize memory usage? I'd like to hear it!  \n\nAlso, do you know of other ways to do cluster analysis on categorical data with many missing data points?",
    "supporting": [
      "bundestag-part-iii_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/panelset-0.2.6/panelset.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/panelset-0.2.6/panelset.js\"></script>\n<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}